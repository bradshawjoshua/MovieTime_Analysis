{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae963448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tmdbsimple as tmdb\n",
    "import os, time,json\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa6777ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading previous MovieTime Analysis notebook dataframes\n",
    "basics = pd.read_csv(\"Data/title_basics.csv.gz\", low_memory = False)\n",
    "akas = pd.read_csv(\"Data/title_akas.csv.gz\", low_memory = False)\n",
    "ratings = pd.read_csv(\"Data/title_ratings.csv.gz\", low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99d182d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 82150 entries, 0 to 82149\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   tconst          82150 non-null  object \n",
      " 1   titleType       82150 non-null  object \n",
      " 2   primaryTitle    82150 non-null  object \n",
      " 3   originalTitle   82150 non-null  object \n",
      " 4   isAdult         82150 non-null  int64  \n",
      " 5   startYear       82150 non-null  int64  \n",
      " 6   endYear         0 non-null      float64\n",
      " 7   runtimeMinutes  82150 non-null  int64  \n",
      " 8   genres          82150 non-null  object \n",
      "dtypes: float64(1), int64(3), object(5)\n",
      "memory usage: 5.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# checking for missing values\n",
    "basics.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c800c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping endYear column, all null\n",
    "basics = basics.drop(columns = [\"endYear\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "255a2c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1342956 entries, 0 to 1342955\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count    Dtype  \n",
      "---  ------           --------------    -----  \n",
      " 0   titleId          1342956 non-null  object \n",
      " 1   ordering         1342956 non-null  int64  \n",
      " 2   title            1342956 non-null  object \n",
      " 3   region           1342956 non-null  object \n",
      " 4   language         3681 non-null     object \n",
      " 5   types            963321 non-null   object \n",
      " 6   attributes       44751 non-null    object \n",
      " 7   isOriginalTitle  1341581 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(6)\n",
      "memory usage: 82.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# checking for missing values\n",
    "akas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bc21205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing null values as unknown\n",
    "akas[\"language\"].fillna(\"Unknown\", inplace = True)\n",
    "akas[\"types\"].fillna(\"Unknown\", inplace = True)\n",
    "akas[\"attributes\"].fillna(\"Unknown\", inplace = True)\n",
    "akas[\"isOriginalTitle\"].fillna(\"Unknown\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "264c4f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1263582 entries, 0 to 1263581\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count    Dtype  \n",
      "---  ------         --------------    -----  \n",
      " 0   tconst         1263582 non-null  object \n",
      " 1   averageRating  1263582 non-null  float64\n",
      " 2   numVotes       1263582 non-null  int64  \n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 28.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# check for missing values\n",
    "ratings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a370e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tmdbsimple in c:\\users\\joshu\\appdata\\roaming\\python\\python310\\site-packages (2.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\joshu\\appdata\\roaming\\python\\python310\\site-packages (from tmdbsimple) (2.28.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\joshu\\appdata\\roaming\\python\\python310\\site-packages (from requests->tmdbsimple) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\joshu\\appdata\\roaming\\python\\python310\\site-packages (from requests->tmdbsimple) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\joshu\\appdata\\roaming\\python\\python310\\site-packages (from requests->tmdbsimple) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\joshu\\appdata\\roaming\\python\\python310\\site-packages (from requests->tmdbsimple) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "# tmdbsimple\n",
    "!pip install tmdbsimple  --no-warn-script-location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ace0aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API credentials\n",
    "with open('/Users/joshu/.secret/tmdb_api.json', 'r') as f:\n",
    "    login = json.load(f)\n",
    "login.keys()\n",
    "\n",
    "import tmdbsimple as tmdb\n",
    "tmdb.API_KEY =  login['api-key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa7857f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating API key\n",
    "tmdb.API_KEY =  login['api-key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55975f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'title_akas.csv.gz',\n",
       " 'title_basics.csv.gz',\n",
       " 'title_ratings.csv.gz']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# designating folder 'Data' to save my API calls\n",
    "FOLDER = \"Data/\"\n",
    "os.makedirs(FOLDER, exist_ok=True)\n",
    "os.listdir(FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad5fda45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my client's desired years\n",
    "YEARS_TO_GET = [2000, 2001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c73b48be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions prior to running loop\n",
    "def read_and_fix_json(JSON_FILE):\n",
    "    \"\"\"Attempts to read in json file of records and fixes the final character\n",
    "    to end with a ] if it errors.\n",
    "    \n",
    "    Args:\n",
    "        JSON_FILE (str): filepath of JSON file\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: the corrected data from the bad json file\n",
    "    \"\"\"\n",
    "    try: \n",
    "        previous_df =  pd.read_json(JSON_FILE)\n",
    "    \n",
    "    ## if read_json throws an error\n",
    "    except:\n",
    "        \n",
    "        ## manually open the json file\n",
    "        with open(JSON_FILE,'r+') as f:\n",
    "            ## Read in the file as a STRING\n",
    "            bad_json = f.read()\n",
    "            \n",
    "            ## if the final character doesn't match first, select the right bracket\n",
    "            first_char = bad_json[0]\n",
    "            final_brackets = {'[':']', \n",
    "                           \"{\":\"}\"}\n",
    "            ## Select expected final brakcet\n",
    "            final_char = final_brackets[first_char]\n",
    "            \n",
    "            ## if the last character in file doen't match the first char, add it\n",
    "            if bad_json[-1] != final_char:\n",
    "                good_json = bad_json[:-1]\n",
    "                good_json+=final_char\n",
    "            else:\n",
    "                raise Exception('ERROR is not due to mismatched final bracket.')\n",
    "            \n",
    "            ## Rewind to start of file and write new good_json to disk\n",
    "            f.seek(0)\n",
    "            f.write(good_json)\n",
    "           \n",
    "        ## Load the json file again now that its fixed\n",
    "        previous_df =  pd.read_json(JSON_FILE)\n",
    "        \n",
    "    return previous_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0925c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_rating(movie_id):\n",
    "    \n",
    "    # getting the movie object for the current id\n",
    "    movie = tmdb.Movies(movie_id)\n",
    "\n",
    "    # save the .info .releases dictionaries\n",
    "    movie_info = movie.info()\n",
    "    \n",
    "    releases = movie.releases()\n",
    "    # looping through countries in releases\n",
    "    for c in releases['countries']:\n",
    "        if c['iso_3166_1' ] =='US':\n",
    "           movie_info['certification'] = c['certification']\n",
    "    return movie_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbde55fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the inner loop  (https://www.geeksforgeeks.org/append-to-json-file-using-python/)\n",
    "def write_json(new_data, filename):   \n",
    "    \n",
    "    with open(filename,'r+') as file:\n",
    "        # First we load existing data into a dict.\n",
    "        file_data = json.load(file)\n",
    "        ## Choose extend or append\n",
    "        if (type(new_data) == list) & (type(file_data) == list):\n",
    "            file_data.extend(new_data)\n",
    "        else:\n",
    "             file_data.append(new_data)\n",
    "        # Sets file's current position at offset.\n",
    "        file.seek(0)\n",
    "        # convert back to json.\n",
    "        json.dump(file_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50830c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ae8ca58da24c94b1df6839f0380c6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "YEARS:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df35dcaca7d4467fadd0091ec0828c5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Movies from 2000:   0%|          | 0/1407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "835b9ec882f04feeb1581ba94f697e5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Movies from 2001:   0%|          | 0/1529 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# outer loop\n",
    "for YEAR in tqdm_notebook(YEARS_TO_GET, desc='YEARS', position=0):\n",
    "    JSON_FILE = f'{FOLDER}tmdb_api_results_{YEAR}.json'\n",
    "    file_exists = os.path.isfile(JSON_FILE)\n",
    "    \n",
    "    if file_exists == False:\n",
    "        with open(JSON_FILE,'w') as f:\n",
    "            json.dump([{'imdb_id':0}],f)\n",
    "            \n",
    "    df = basics.loc[basics['startYear']==YEAR].copy()\n",
    "    movie_ids = df['tconst'].copy()\n",
    "    previous_df = read_and_fix_json(JSON_FILE)\n",
    "    movie_ids_to_get = movie_ids[~movie_ids.isin(previous_df['imdb_id'])]        \n",
    "\n",
    "    # inner loop\n",
    "    for movie_id in tqdm_notebook(movie_ids_to_get, \n",
    "                                  desc=f'Movies from {YEAR}', \n",
    "                                  position=1, leave=True):\n",
    "        try:\n",
    "            temp = movie_rating(movie_id)\n",
    "            write_json(temp, JSON_FILE)\n",
    "            time.sleep(0.02)\n",
    "            \n",
    "        except Exception as e:\n",
    "            continue\n",
    "            \n",
    "    final_year_df = pd.read_json(JSON_FILE)\n",
    "    final_year_df.to_csv(f\"{FOLDER}final_tmdb_data_{YEAR}.csv.gz\", compression=\"gzip\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
